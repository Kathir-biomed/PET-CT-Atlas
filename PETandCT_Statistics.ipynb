{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook is used for calculating the the Positron Emission Tomography (PET) and the Computed Tomography (CT) statistics such as Hounsfield Unit (HU) mean, Hounsfield Unit Standard Deviation, Standardized Uptake Value (SUV) mean, SUV peak, and SUV max. It also computes the volume of the organs of interest in ml.\n",
    "1. Import the necessary libraries\n",
    "2. Input files that are required for statistics computation. \n",
    "((i) DICOM file PET\n",
    "(i) DICOM file CT\n",
    "(iii) NIfTI file PET\n",
    "(iv) NIfTI file CT\n",
    "(v) Segmented organs)\n",
    "3. Extract the requird metadata from the DICOM and store it. (Explanation: We are performing all of our calculations on NIfTI file and since NIfTI file does not have our necessary metadata in them, we need to extract the required metadata from the DICOM and use it for our calculations with NIfTI file)\n",
    "4. Main functions\n",
    "5. Output storage path (Excel file path to store the output)\n",
    "6. Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydicom nibabel pandas matplotlib scipy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Required input files path: (You would need to provide any one of the .dcm file just for extracting the necessary metadata from them. Specify the folder where all your 117 segmented organ classes are stored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Personal/ABX/patient_1/segmentations_sample/aorta.nii.gz\n",
      "7084.040157022099\n"
     ]
    }
   ],
   "source": [
    "#DICOM file paths\n",
    "pet_dicom_file_path = \"C:/Personal/ABX/patient_1/DICOM/PETCT_0117d7f11f/09-13-2001-NA-PET-CT Ganzkoerper  primaer mit KM-68547/12.000000-PET corr.-44501/6-075.dcm\"\n",
    "ct_dicom_file_path = \"C:/Personal/ABX/patient_1/DICOM/PETCT_0117d7f11f/09-13-2001-NA-PET-CT Ganzkoerper  primaer mit KM-68547/5.000000-GK p.v.2-84770/1-001.dcm\"\n",
    "\n",
    "# NIfTI file paths\n",
    "nifti_file_path_pet = \"C:/Personal/ABX/patient_1/NIFTI/PETCT_0117d7f11f/09-13-2001-NA-PET-CT Ganzkoerper  primaer mit KM-68547/PET.nii.gz\"\n",
    "nifti_file_path_ct = \"C:/Personal/ABX/patient_1/NIFTI/PETCT_0117d7f11f/09-13-2001-NA-PET-CT Ganzkoerper  primaer mit KM-68547/CTres.nii.gz\"\n",
    "\n",
    "# Segmented organs pathh\n",
    "segmented_organs_folder = \"C:/Personal/ABX/patient_1/segmentations\"\n",
    "\n",
    "#For SUR\n",
    "aorta_segmented_nifti_path = os.path.join(segmented_organs_folder, \"aorta.nii.gz\")\n",
    "\n",
    "# Normalize the path to use forward slashes\n",
    "aorta_segmented_nifti_path = aorta_segmented_nifti_path.replace('\\\\', '/')\n",
    "print(aorta_segmented_nifti_path)\n",
    "\n",
    "# Path to the aorta segmented NIfTI file\n",
    "aorta_segmented_nifti_path = os.path.join(segmented_organs_folder, \"aorta.nii.gz\").replace('\\\\', '/')\n",
    "# Load the aorta segmented NIfTI file\n",
    "aorta_segmented_img = nib.load(aorta_segmented_nifti_path)\n",
    "aorta_segmented_data = aorta_segmented_img.get_fdata()\n",
    "\n",
    "# Load PET NIfTI file for aorta activity calculation\n",
    "pet_img_for_aorta = nib.load(nifti_file_path_pet)\n",
    "pet_data_for_aorta = pet_img_for_aorta.get_fdata()\n",
    "\n",
    "# Calculate the mean activity within the aorta's segmentation\n",
    "aorta_mean_activity = np.mean(pet_data_for_aorta[aorta_segmented_data > 0])\n",
    "\n",
    "aorta_activity = aorta_mean_activity\n",
    "\n",
    "print(aorta_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the required metadata from the DICOM and store it in an array named \"metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'patient_id': 'PETCT_0117d7f11f', 'weight': '65.0', 'series_date': '20010913', 'series_time': datetime.timedelta(seconds=31322), 'acquisition_date': '20010913', 'acquisition_time': datetime.timedelta(seconds=31957, microseconds=29), 'rescale_slope_pet': '1.77409', 'rescale_intercept_pet': '0.0', 'acquisition_time_pet': '085237.000029', 'rescale_slope_ct': '0.9236', 'rescale_intercept_ct': '-1.6565', 'acquisition_time_ct': '083125.539000', 'Radiopharmaceutical_start_time': '074700.000000', 'radionuclide_total_dose': '313000000.0', 'radionuclide_half_life': '6586.2'}\n"
     ]
    }
   ],
   "source": [
    "def get_data_element_value(data_element):\n",
    "    # If the element is None, return 'Attribute not found'\n",
    "    if data_element is None:\n",
    "        return 'Attribute not found'\n",
    "    # If the element is a pydicom DataElement, return its value\n",
    "    elif isinstance(data_element, pydicom.dataelem.DataElement):\n",
    "        return data_element.value\n",
    "    # If the element is already a value (e.g., a string), return it directly\n",
    "    else:\n",
    "        return data_element\n",
    "    \n",
    "def dicom_time_to_timedelta(dicom_time_str):\n",
    "    #Time is in HHMMSS.FFFFFF format\n",
    "    if dicom_time_str:\n",
    "        hours = int(dicom_time_str[0:2])\n",
    "        minutes = int(dicom_time_str[2:4])\n",
    "        seconds = float(dicom_time_str[4:])\n",
    "        return timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "    return None\n",
    "\n",
    "def extract_metadata(pet_dicom_file_path, ct_dicom_file_path):\n",
    "    pet_dicom_data = pydicom.dcmread(pet_dicom_file_path)\n",
    "    ct_dicom_data = pydicom.dcmread(ct_dicom_file_path)\n",
    "\n",
    "    metadata = {\n",
    "        #common\n",
    "        'patient_id': get_data_element_value(pet_dicom_data.PatientID),\n",
    "        'weight': get_data_element_value(pet_dicom_data.PatientWeight),\n",
    "        'series_date': get_data_element_value(pet_dicom_data.SeriesDate),\n",
    "        'series_time': get_data_element_value(pet_dicom_data.SeriesTime),\n",
    "        'acquisition_date': get_data_element_value(pet_dicom_data.AcquisitionDate),\n",
    "        'acquisition_time': get_data_element_value(pet_dicom_data.AcquisitionTime),\n",
    "\n",
    "\n",
    "        #PET specific\n",
    "        'rescale_slope_pet': get_data_element_value(pet_dicom_data.get((0x0028, 0x1053))),\n",
    "        'rescale_intercept_pet': get_data_element_value(pet_dicom_data.get((0x0028, 0x1052))),\n",
    "        'acquisition_time_pet': get_data_element_value(pet_dicom_data.AcquisitionTime),\n",
    "\n",
    "\n",
    "        #CT specific\n",
    "        'rescale_slope_ct': get_data_element_value(ct_dicom_data.get((0x0019, 0x1092))),\n",
    "        'rescale_intercept_ct': get_data_element_value(ct_dicom_data.get((0x0019, 0x1093))),\n",
    "        'acquisition_time_ct': get_data_element_value(ct_dicom_data.AcquisitionTime),\n",
    "    }\n",
    "\n",
    "    metadata['series_time'] = dicom_time_to_timedelta(metadata['series_time'])\n",
    "    metadata['acquisition_time'] = dicom_time_to_timedelta(metadata['acquisition_time'])\n",
    "    #metadata['acquisition_time_pet'] = dicom_time_to_timedelta(metadata['acquisition_time_pet'])\n",
    "    #metadata['acquisition_time_ct'] = dicom_time_to_timedelta(metadata['acquisition_time_ct'])\n",
    "\n",
    "    # Extract Radionuclide Information from the sequence\n",
    "    rad_info_sequence = pet_dicom_data.get((0x0054, 0x0016), None)\n",
    "    if rad_info_sequence:\n",
    "        rad_info_item = rad_info_sequence[0]\n",
    "        metadata['Radiopharmaceutical_start_time'] = get_data_element_value(rad_info_item.get((0x0018, 0x1072)))\n",
    "        metadata['radionuclide_total_dose'] = get_data_element_value(rad_info_item.get((0x0018, 0x1074)))\n",
    "        metadata['radionuclide_half_life'] = get_data_element_value(rad_info_item.get((0x0018, 0x1075)))\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Read DICOM metadata\n",
    "metadata = extract_metadata(pet_dicom_file_path, ct_dicom_file_path)\n",
    "\n",
    "print(metadata)\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Convert DICOM time string to Python datetime object\n",
    "def convert_dicom_time_to_datetime(dicom_time_str):\n",
    "    return datetime.strptime(dicom_time_str, '%H%M%S.%f')\n",
    "\n",
    "# Convert a timedelta to DICOM time format\n",
    "def convert_timedelta_to_dicom_time(delta):\n",
    "    # Extract hours, minutes, seconds and microseconds\n",
    "    hours, remainder = divmod(delta.seconds, 3600)\n",
    "    minutes, seconds = divmod(remainder, 60)\n",
    "    microseconds = delta.microseconds\n",
    "    # Construct a time string\n",
    "    return f'{hours:02d}{minutes:02d}{seconds:02d}.{microseconds:06d}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Main functions to calculate the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hu_metrics(ct_nifti_path, segmented_nifti_path, rescale_slope_ct, rescale_intercept_ct):\n",
    "    # Load CT NIfTI file\n",
    "    ct_img = nib.load(ct_nifti_path)\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Load segmented NIfTI file for HU calculation and mask metrics\n",
    "    segmented_img = nib.load(segmented_nifti_path)\n",
    "    segmented_data = segmented_img.get_fdata()\n",
    "\n",
    "    # Calculate HU values for the organ region\n",
    "    hu_values_organ = (ct_data * segmented_data * rescale_slope_ct) + rescale_intercept_ct\n",
    "\n",
    "    # Initialize variables with default values\n",
    "    hu_mean_organ, hu_std_organ, mask_volume_ml = np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check if there are valid data points in the segmented region\n",
    "    valid_data_points = hu_values_organ[segmented_data > 0]\n",
    "\n",
    "    if valid_data_points.size > 0:\n",
    "        # Calculate HU mean and standard deviation for the organ\n",
    "        hu_mean_organ = valid_data_points.mean()\n",
    "        hu_std_organ = valid_data_points.std()\n",
    "\n",
    "        print(\"HU Mean:\")\n",
    "        print(hu_mean_organ)\n",
    "\n",
    "        print(\"HU Standard Deviation:\")\n",
    "        print(hu_std_organ)\n",
    "\n",
    "    else:\n",
    "        print(\"No valid data points in the segmented organ region. Unable to calculate HU metrics.\")\n",
    "\n",
    "    # Calculate mask volume in milliliters\n",
    "    voxel_volume_mm3 = np.prod(ct_img.header.get_zooms())  # Voxel volume in mm^3\n",
    "    mask_volume_ml = np.sum(segmented_data) * voxel_volume_mm3 / 1000.0  # Convert to milliliters\n",
    "\n",
    "    print(\"Mask Volume (ml):\")\n",
    "    print(mask_volume_ml)\n",
    "\n",
    "    # finding non-zero voxels at the border of segmented volumes\n",
    "    non_zero_voxels = int(\n",
    "        (segmented_data[0, :, :].any() or segmented_data[-1, :, :].any() or\n",
    "         segmented_data[:, 0, :].any() or segmented_data[:, -1, :].any() or\n",
    "         segmented_data[:, :, 0].any() or segmented_data[:, :, -1].any())\n",
    "    )\n",
    "\n",
    "    print(\"Non-zero voxel:\", non_zero_voxels)\n",
    "\n",
    "    return hu_mean_organ, hu_std_organ, mask_volume_ml, non_zero_voxels\n",
    "\n",
    "def calculate_organ_suv(nifti_file_path, segmented_nifti_path, weight, radionuclide_half_life, series_time, acquisition_time, radionuclide_total_dose, rescale_slope_pet, rescale_intercept_pet):\n",
    "    # Load PET NIfTI file\n",
    "    pet_img = nib.load(nifti_file_path)\n",
    "    pet_data = pet_img.get_fdata()\n",
    "\n",
    "    # Apply a median filter to reduce noise\n",
    "    filtered_pet_data = median_filter(pet_data, size=5)  # The size parameter may need adjustment\n",
    "\n",
    "    # Load segmented NIfTI file\n",
    "    segmented_img = nib.load(segmented_nifti_path)\n",
    "    segmented_data = segmented_img.get_fdata()\n",
    "\n",
    "    # Calculate decayed dose\n",
    "    decay_time = (acquisition_time - series_time).total_seconds()\n",
    "    decayed_dose = radionuclide_total_dose * (2 ** (-decay_time / radionuclide_half_life))\n",
    "\n",
    "    # Calculate SUVbw scale factor\n",
    "    suvbw_scale_factor = (weight * 1000) / decayed_dose\n",
    "\n",
    "    # Use the filtered PET data for SUV calculations\n",
    "    suvbw_organ = (filtered_pet_data * segmented_data * rescale_slope_pet + rescale_intercept_pet) * suvbw_scale_factor\n",
    "\n",
    "    # Initialize variables with default values\n",
    "    mean_suvbw_organ, suv_peak_organ, suv_max_organ, suv_std_organ = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check if there are valid data points in the segmented region\n",
    "    valid_data_points = suvbw_organ[segmented_data > 0]\n",
    "\n",
    "    if valid_data_points.size > 0:\n",
    "        # Calculate the mean SUVbw value for the organ\n",
    "        mean_suvbw_organ = valid_data_points.mean()\n",
    "        print(\"Mean SUVbw:\")\n",
    "        print(mean_suvbw_organ)\n",
    "\n",
    "        # Calculate SUV Max for the organ\n",
    "        suv_max_organ = valid_data_points.max()\n",
    "        print(\"SUV Max:\")\n",
    "        print(suv_max_organ)\n",
    "\n",
    "        # Calculate SUV Standard Deviation for the organ\n",
    "        suv_std_organ = valid_data_points.std()\n",
    "        print(\"SUV Standard Deviation:\")\n",
    "        print(suv_std_organ)\n",
    "\n",
    "        # Find the spatial coordinates (indices) of the maximum SUV voxel\n",
    "        max_suv_index = np.unravel_index(np.argmax(suvbw_organ), suvbw_organ.shape)\n",
    "\n",
    "        # Define a small region (1 cm^3 sphere) around the maximum SUV voxel\n",
    "        sphere_radius = int(np.ceil(1 / pet_img.header.get_zooms()[0]))  # in voxel units\n",
    "        region_around_max_suv = suvbw_organ[\n",
    "            max(0, max_suv_index[0] - sphere_radius):min(suvbw_organ.shape[0], max_suv_index[0] + sphere_radius + 1),\n",
    "            max(0, max_suv_index[1] - sphere_radius):min(suvbw_organ.shape[1], max_suv_index[1] + sphere_radius + 1),\n",
    "            max(0, max_suv_index[2] - sphere_radius):min(suvbw_organ.shape[2], max_suv_index[2] + sphere_radius + 1)\n",
    "        ]\n",
    "\n",
    "        # Calculate SUV Peak for the organ (average value within the 1-cm^3 sphere)\n",
    "        # Calculate SUV Peak for the organ using median (more robust to noise)\n",
    "        suv_peak_organ = np.median(region_around_max_suv[region_around_max_suv > 0])\n",
    "        #suv_peak_organ = region_around_max_suv.mean()\n",
    "        print(\"SUV Peak:\")\n",
    "        print(suv_peak_organ)\n",
    "\n",
    "    else:\n",
    "        print(\"No valid data points in the segmented organ region. Unable to calculate SUV metrics.\")\n",
    "\n",
    "    return mean_suvbw_organ, suv_peak_organ, suv_max_organ, suv_std_organ\n",
    "\n",
    "def calculate_organ_sur(nifti_file_path, segmented_nifti_path, aorta_activity, rescale_slope_pet, rescale_intercept_pet):\n",
    "    # Load PET NIfTI file\n",
    "    pet_img = nib.load(nifti_file_path)\n",
    "    pet_data = pet_img.get_fdata()\n",
    "\n",
    "    # Apply a median filter to reduce noise\n",
    "    filtered_pet_data = median_filter(pet_data, size=5)\n",
    "\n",
    "    # Load segmented NIfTI file\n",
    "    segmented_img = nib.load(segmented_nifti_path)\n",
    "    segmented_data = segmented_img.get_fdata()\n",
    "\n",
    "    # Calculate SUR by normalizing PET data with the aorta activity\n",
    "    sur_organ = ((filtered_pet_data * segmented_data * rescale_slope_pet) + rescale_intercept_pet) / aorta_activity\n",
    "\n",
    "    # Initialize variables\n",
    "    mean_sur_organ, sur_peak_organ, sur_max_organ, sur_std_organ = np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check for valid data points in the segmented region\n",
    "    valid_data_points = sur_organ[segmented_data > 0]\n",
    "\n",
    "    if valid_data_points.size > 0:\n",
    "        mean_sur_organ = valid_data_points.mean()\n",
    "        sur_max_organ = valid_data_points.max()\n",
    "        sur_std_organ = valid_data_points.std()\n",
    "\n",
    "        # Calculate SUR Peak\n",
    "        max_sur_index = np.unravel_index(np.argmax(sur_organ), sur_organ.shape)\n",
    "        sphere_radius = int(np.ceil(1 / pet_img.header.get_zooms()[0]))\n",
    "        region_around_max_sur = sur_organ[\n",
    "            max(0, max_sur_index[0] - sphere_radius):min(sur_organ.shape[0], max_sur_index[0] + sphere_radius + 1),\n",
    "            max(0, max_sur_index[1] - sphere_radius):min(sur_organ.shape[1], max_sur_index[1] + sphere_radius + 1),\n",
    "            max(0, max_sur_index[2] - sphere_radius):min(sur_organ.shape[2], max_sur_index[2] + sphere_radius + 1)\n",
    "        ]\n",
    "        sur_peak_organ = np.median(region_around_max_sur[region_around_max_sur > 0])\n",
    "\n",
    "    return mean_sur_organ, sur_peak_organ, sur_max_organ, sur_std_organ\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Output storage path: (Simply specify a path to your folder of interest. An excel sheet will be generated and all the outputs will be stored there.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_excel_file_path = f\"C:/Personal/ABX/patient_1/Results/{metadata['patient_id']}_08_02_24_patient1.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Main code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "010537.000029\n",
      "002111.461029\n",
      "HU Mean:\n",
      "69.71785781821505\n",
      "HU Standard Deviation:\n",
      "34.52569762546819\n",
      "Mask Volume (ml):\n",
      "3.7323062896728514\n",
      "Non-zero voxel: 0\n",
      "Mean SUVbw:\n",
      "2.313970935087981\n",
      "SUV Max:\n",
      "2.796639401744264\n",
      "SUV Standard Deviation:\n",
      "0.20839577766513648\n",
      "SUV Peak:\n",
      "2.660894898955162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kathir\\AppData\\Local\\Temp\\ipykernel_10996\\844011967.py:82: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  existing_df = pd.concat([existing_df, new_df], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU Mean:\n",
      "131.717836332247\n",
      "HU Standard Deviation:\n",
      "30.339087703876437\n",
      "Mask Volume (ml):\n",
      "195.4359983482361\n",
      "Non-zero voxel: 0\n",
      "Mean SUVbw:\n",
      "2.7268283675296376\n",
      "SUV Max:\n",
      "4.747711508818379\n",
      "SUV Standard Deviation:\n",
      "0.2719037868685261\n",
      "SUV Peak:\n",
      "4.2118424458353925\n",
      "HU Mean:\n",
      "48.36886761773828\n",
      "HU Standard Deviation:\n",
      "27.179416912395066\n",
      "Mask Volume (ml):\n",
      "1124.1582134284972\n",
      "Non-zero voxel: 1\n",
      "Mean SUVbw:\n",
      "7.748612786710046\n",
      "SUV Max:\n",
      "14.469652698616182\n",
      "SUV Standard Deviation:\n",
      "2.140266620054144\n",
      "SUV Peak:\n",
      "12.233801470532763\n",
      "PET-CT Statistics: C:/Personal/ABX/patient_2/Results/PETCT_0117d7f11f_08_02_24_patient1.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get a list of all NIfTI files in the \"segmented_organs\" folder\n",
    "segmented_nifti_paths = [os.path.join(segmented_organs_folder, file) for file in os.listdir(segmented_organs_folder) if file.endswith(\".nii.gz\")]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "existing_df = pd.DataFrame(columns=[\n",
    "    'Patient ID', 'Inj Start [HHMMSS.FFFFFF]', 'CT Start [HHMMSS.FFFFFF]', 'PET Start [HHMMSS.FFFFFF]', 'Inj-PET [HHMMSS.FFFFFF]', 'CT-PET [HHMMSS.FFFFFF]', 'Organ', 'HU Mean', 'HU Std Dev', 'SUV Mean', 'SUV Std Dev', 'SUV Peak', 'SUV Max', 'SUR Mean', 'SUR Std Dev', 'SUR Peak', 'SUR Max', 'Non-zero Voxel', 'Mask Volume (ml)'\n",
    "])\n",
    "# Convert time strings to datetime objects\n",
    "radiopharmaceutical_start_datetime = convert_dicom_time_to_datetime(metadata['Radiopharmaceutical_start_time'])\n",
    "acquisition_time_pet_datetime = convert_dicom_time_to_datetime(metadata['acquisition_time_pet'])\n",
    "acquisition_time_ct_datetime = convert_dicom_time_to_datetime(metadata['acquisition_time_ct'])\n",
    "\n",
    "Injection_to_pet = acquisition_time_pet_datetime - radiopharmaceutical_start_datetime\n",
    "ct_to_pet = acquisition_time_pet_datetime - acquisition_time_ct_datetime\n",
    "\n",
    "# Convert the time difference to DICOM time format\n",
    "Injection_to_pet_time_diff = convert_timedelta_to_dicom_time(Injection_to_pet)\n",
    "ct_to_pet_time_diff = convert_timedelta_to_dicom_time(ct_to_pet)\n",
    "\n",
    "print(Injection_to_pet_time_diff)\n",
    "print(ct_to_pet_time_diff)\n",
    "\n",
    "\n",
    "# Iterate through segmented organ NIfTI files\n",
    "for segmented_nifti_path in segmented_nifti_paths:\n",
    "\n",
    "    # Calculate HU metrics\n",
    "    hu_mean, hu_std, mask_volume_ml, non_zero_voxels = calculate_hu_metrics(nifti_file_path_ct, segmented_nifti_path, metadata['rescale_slope_ct'], metadata['rescale_intercept_ct'])\n",
    "\n",
    "    # Calculate SUV metrics\n",
    "    #pet_weight = 65.0  # Assuming a constant weight for debuging\n",
    "    #pet_radionuclide_half_life = 6586.2  # Assuming a constant half-life for debugging\n",
    "    pet_mean_suvbw, pet_suv_peak, pet_suv_max, pet_suv_std = calculate_organ_suv(nifti_file_path_pet, segmented_nifti_path, metadata['weight'], metadata['radionuclide_half_life'], metadata['series_time'], metadata['acquisition_time'], metadata['radionuclide_total_dose'], metadata['rescale_slope_pet'], metadata['rescale_intercept_pet'])\n",
    "\n",
    "    # Calculate SUR metrics\n",
    "    pet_mean_sur, pet_sur_peak, pet_sur_max, pet_sur_std = calculate_organ_sur(nifti_file_path_pet, segmented_nifti_path, aorta_activity, metadata['rescale_slope_pet'], metadata['rescale_intercept_pet'])\n",
    "\n",
    "    # Extract organ name from the segmented nifti file name\n",
    "    organ_name = os.path.splitext(os.path.splitext(os.path.basename(segmented_nifti_path))[0])[0]\n",
    "\n",
    "    #Injection_to_pet_time_diff = acquisition_time_pet_datetime - radiopharmaceutical_start_datetime\n",
    "    #ct_to_pet_time_diff = acquisition_time_ct_datetime - acquisition_time_ct_datetime\n",
    "\n",
    "    # Extract patient ID from nifti_file_path\n",
    "    match = re.search(r'/NIFTI/(.*?)/', nifti_file_path_ct)\n",
    "    if match:\n",
    "        patient_id = match.group(1)\n",
    "    else:\n",
    "        print(\"Unable to extract Patient ID from nifti_file_path.\")\n",
    "\n",
    "    # Determine the index of the next empty row\n",
    "    next_index = len(existing_df) + 1\n",
    "\n",
    "    # Append the new results to the existing DataFrame with the calculated index\n",
    "    new_data = {\n",
    "        'Patient ID': [patient_id],\n",
    "\n",
    "        'Inj Start [HHMMSS.FFFFFF]' : [metadata['Radiopharmaceutical_start_time']],\n",
    "        'CT Start [HHMMSS.FFFFFF]': [metadata['acquisition_time_ct']], #metadata['rescale_slope_ct']\n",
    "        'PET Start [HHMMSS.FFFFFF]': [metadata['acquisition_time_pet']], \n",
    "        'Inj-PET [HHMMSS.FFFFFF]': [Injection_to_pet_time_diff],\n",
    "        'CT-PET [HHMMSS.FFFFFF]': [ct_to_pet_time_diff],\n",
    "\n",
    "        'Organ': [organ_name],\n",
    "        'HU Mean': [hu_mean],\n",
    "        'HU Std Dev': [hu_std],\n",
    "        'SUV Mean': [pet_mean_suvbw],\n",
    "        'SUV Std Dev': [pet_suv_std],\n",
    "        'SUV Peak': [pet_suv_peak],\n",
    "        'SUV Max': [pet_suv_max],\n",
    "        'SUR Mean': [pet_mean_sur],\n",
    "        'SUR Std Dev': [pet_sur_std],\n",
    "        'SUR Peak' : [pet_sur_peak],\n",
    "        'SUR Max' : [pet_sur_max],\n",
    "        'Non-zero Voxel' : [non_zero_voxels],\n",
    "        'Mask Volume (ml)': [mask_volume_ml],\n",
    "    }\n",
    "\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    new_df.index = [next_index]\n",
    "\n",
    "    existing_df = pd.concat([existing_df, new_df], ignore_index=False)\n",
    "\n",
    "# Save the updated DataFrame to the Excel file without the index column\n",
    "existing_df.to_excel(existing_excel_file_path, index=False)\n",
    "\n",
    "# Print a message indicating successful export\n",
    "print(f\"PET-CT Statistics: {existing_excel_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
