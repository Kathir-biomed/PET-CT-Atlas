{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python notebook is used for calculating the the Positron Emission Tomography (PET) and the Computed Tomography (CT) statistics such as Hounsfield Unit (HU) mean, Hounsfield Unit Standard Deviation, Standardized Uptake Value (SUV) mean, SUV peak, and SUV max. It also computes the volume of the organs of interest in ml.\n",
    "1. Import the necessary libraries\n",
    "2. Input files that are required for statistics computation. \n",
    "((i) DICOM file PET\n",
    "(i) DICOM file CT\n",
    "(iii) NIfTI file PET\n",
    "(iv) NIfTI file CT\n",
    "(v) Segmented organs)\n",
    "3. Extract the requird metadata from the DICOM and store it. (Explanation: We are performing all of our calculations on NIfTI file and since NIfTI file does not have our necessary metadata in them, we need to extract the required metadata from the DICOM and use it for our calculations with NIfTI file)\n",
    "4. Main functions\n",
    "5. Output storage path (Excel file path to store the output)\n",
    "6. Main code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "from datetime import timedelta\n",
    "from scipy.ndimage import median_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Required input files path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DICOM file paths\n",
    "pet_dicom_file_path = \"C:/Personal/ABX/patient_2/DICOM/PETCT_4ef69de4e1/10-25-2002-NA-PET-CT Teilkoerper  primaer mit KM-18049/9.000000-PET corr.-01846/1-001.dcm\"\n",
    "ct_dicom_file_path = \"C:/Personal/ABX/patient_2/DICOM/PETCT_4ef69de4e1/10-25-2002-NA-PET-CT Teilkoerper  primaer mit KM-18049/4.000000-THA p.v.3-96290/1-001.dcm\"\n",
    "\n",
    "# NIfTI file paths\n",
    "nifti_file_path_pet = \"C:/Personal/ABX/patient_2/NIFTI/PETCT_4ef69de4e1/10-25-2002-NA-PET-CT Teilkoerper  primaer mit KM-18049/PET.nii.gz\"\n",
    "nifti_file_path_ct = \"C:/Personal/ABX/patient_2/NIFTI/PETCT_4ef69de4e1/10-25-2002-NA-PET-CT Teilkoerper  primaer mit KM-18049/CTres.nii.gz\"\n",
    "\n",
    "# Segmented organs pathh\n",
    "segmented_organs_folder = \"C:/Personal/ABX/patient_2/segmentations_pre\"\n",
    "\n",
    "#Get a list of all NIfTI files in the \"segmented_organs\" folder\n",
    "segmented_nifti_paths = [os.path.join(segmented_organs_folder, file) for file in os.listdir(segmented_organs_folder) if file.endswith(\".nii.gz\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Extract the required metadata from the DICOM and store it in an array named \"metadata\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_element_value(data_element):\n",
    "    # If the element is None, return 'Attribute not found'\n",
    "    if data_element is None:\n",
    "        return 'Attribute not found'\n",
    "    # If the element is a pydicom DataElement, return its value\n",
    "    elif isinstance(data_element, pydicom.dataelem.DataElement):\n",
    "        return data_element.value\n",
    "    # If the element is already a value (e.g., a string), return it directly\n",
    "    else:\n",
    "        return data_element\n",
    "    \n",
    "def dicom_time_to_timedelta(dicom_time_str):\n",
    "    #Time is in HHMMSS.FFFFFF format\n",
    "    if dicom_time_str:\n",
    "        hours = int(dicom_time_str[0:2])\n",
    "        minutes = int(dicom_time_str[2:4])\n",
    "        seconds = float(dicom_time_str[4:])\n",
    "        return timedelta(hours=hours, minutes=minutes, seconds=seconds)\n",
    "    return None\n",
    "\n",
    "def extract_metadata(pet_dicom_file_path, ct_dicom_file_path):\n",
    "    pet_dicom_data = pydicom.dcmread(pet_dicom_file_path)\n",
    "    ct_dicom_data = pydicom.dcmread(ct_dicom_file_path)\n",
    "\n",
    "    metadata = {\n",
    "        'patient_id': get_data_element_value(pet_dicom_data.PatientID),\n",
    "        'weight': get_data_element_value(pet_dicom_data.PatientWeight),\n",
    "        'series_date': get_data_element_value(pet_dicom_data.SeriesDate),\n",
    "        'series_time': get_data_element_value(pet_dicom_data.SeriesTime),\n",
    "        'acquisition_date': get_data_element_value(pet_dicom_data.AcquisitionDate),\n",
    "        'acquisition_time': get_data_element_value(pet_dicom_data.AcquisitionTime),\n",
    "        'rescale_slope_pet': get_data_element_value(pet_dicom_data.get((0x0028, 0x1053))),\n",
    "        'rescale_intercept_pet': get_data_element_value(pet_dicom_data.get((0x0028, 0x1052))),\n",
    "        'rescale_slope_ct': get_data_element_value(ct_dicom_data.get((0x0019, 0x1092))),\n",
    "        'rescale_intercept_ct': get_data_element_value(ct_dicom_data.get((0x0019, 0x1093)))\n",
    "    }\n",
    "    metadata['series_time'] = dicom_time_to_timedelta(metadata['series_time'])\n",
    "    metadata['acquisition_time'] = dicom_time_to_timedelta(metadata['acquisition_time'])\n",
    "    # Extract Radionuclide Information from the sequence\n",
    "    rad_info_sequence = pet_dicom_data.get((0x0054, 0x0016), None)\n",
    "    if rad_info_sequence:\n",
    "        rad_info_item = rad_info_sequence[0]\n",
    "        metadata['radionuclide_total_dose'] = get_data_element_value(rad_info_item.get((0x0018, 0x1074)))\n",
    "        metadata['radionuclide_half_life'] = get_data_element_value(rad_info_item.get((0x0018, 0x1075)))\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# Read DICOM metadata\n",
    "metadata = extract_metadata(pet_dicom_file_path, ct_dicom_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Main functions to calculate the statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_hu_metrics(ct_nifti_path, segmented_nifti_path, rescale_slope_ct, rescale_intercept_ct):\n",
    "    # Load CT NIfTI file\n",
    "    ct_img = nib.load(ct_nifti_path)\n",
    "    ct_data = ct_img.get_fdata()\n",
    "\n",
    "    # Load segmented NIfTI file for HU calculation and mask metrics\n",
    "    segmented_img = nib.load(segmented_nifti_path)\n",
    "    segmented_data = segmented_img.get_fdata()\n",
    "\n",
    "    # Calculate HU values for the organ region\n",
    "    hu_values_organ = (ct_data * segmented_data * rescale_slope_ct) + rescale_intercept_ct\n",
    "\n",
    "    # Initialize variables with default values\n",
    "    hu_mean_organ, hu_std_organ, mask_volume_ml = np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check if there are valid data points in the segmented region\n",
    "    valid_data_points = hu_values_organ[segmented_data > 0]\n",
    "\n",
    "    if valid_data_points.size > 0:\n",
    "        # Calculate HU mean and standard deviation for the organ\n",
    "        hu_mean_organ = valid_data_points.mean()\n",
    "        hu_std_organ = valid_data_points.std()\n",
    "\n",
    "        print(\"HU Mean:\")\n",
    "        print(hu_mean_organ)\n",
    "\n",
    "        print(\"HU Standard Deviation:\")\n",
    "        print(hu_std_organ)\n",
    "\n",
    "    else:\n",
    "        print(\"No valid data points in the segmented organ region. Unable to calculate HU metrics.\")\n",
    "\n",
    "    # Calculate mask volume in milliliters\n",
    "    voxel_volume_mm3 = np.prod(ct_img.header.get_zooms())  # Voxel volume in mm^3\n",
    "    mask_volume_ml = np.sum(segmented_data) * voxel_volume_mm3 / 1000.0  # Convert to milliliters\n",
    "\n",
    "    print(\"Mask Volume (ml):\")\n",
    "    print(mask_volume_ml)\n",
    "\n",
    "    return hu_mean_organ, hu_std_organ, mask_volume_ml\n",
    "\n",
    "def calculate_organ_suv(nifti_file_path, segmented_nifti_path, weight, radionuclide_half_life, series_time, acquisition_time, radionuclide_total_dose, rescale_slope_pet, rescale_intercept_pet):\n",
    "    # Load PET NIfTI file\n",
    "    pet_img = nib.load(nifti_file_path)\n",
    "    pet_data = pet_img.get_fdata()\n",
    "\n",
    "    # Apply a median filter to reduce noise\n",
    "    filtered_pet_data = median_filter(pet_data, size=5)  # The size parameter may need adjustment\n",
    "\n",
    "    # Load segmented NIfTI file\n",
    "    segmented_img = nib.load(segmented_nifti_path)\n",
    "    segmented_data = segmented_img.get_fdata()\n",
    "\n",
    "    # Calculate decayed dose\n",
    "    decay_time = (acquisition_time - series_time).total_seconds()\n",
    "    decayed_dose = radionuclide_total_dose * (2 ** (-decay_time / radionuclide_half_life))\n",
    "\n",
    "    # Calculate SUVbw scale factor\n",
    "    suvbw_scale_factor = (weight * 1000) / decayed_dose\n",
    "\n",
    "    # Use the filtered PET data for SUV calculations\n",
    "    suvbw_organ = (filtered_pet_data * segmented_data * rescale_slope_pet + rescale_intercept_pet) * suvbw_scale_factor\n",
    "\n",
    "    # Initialize variables with default values\n",
    "    mean_suvbw_organ, suv_peak_organ, suv_max_organ = np.nan, np.nan, np.nan\n",
    "\n",
    "    # Check if there are valid data points in the segmented region\n",
    "    valid_data_points = suvbw_organ[segmented_data > 0]\n",
    "\n",
    "    if valid_data_points.size > 0:\n",
    "        # Calculate the mean SUVbw value for the organ\n",
    "        mean_suvbw_organ = valid_data_points.mean()\n",
    "        print(\"Mean SUVbw:\")\n",
    "        print(mean_suvbw_organ)\n",
    "\n",
    "        # Calculate SUV Max for the organ\n",
    "        suv_max_organ = valid_data_points.max()\n",
    "        print(\"SUV Max:\")\n",
    "        print(suv_max_organ)\n",
    "\n",
    "        # Find the spatial coordinates (indices) of the maximum SUV voxel\n",
    "        max_suv_index = np.unravel_index(np.argmax(suvbw_organ), suvbw_organ.shape)\n",
    "\n",
    "        # Define a small region (1 cm^3 sphere) around the maximum SUV voxel\n",
    "        sphere_radius = int(np.ceil(1 / pet_img.header.get_zooms()[0]))  # in voxel units\n",
    "        region_around_max_suv = suvbw_organ[\n",
    "            max(0, max_suv_index[0] - sphere_radius):min(suvbw_organ.shape[0], max_suv_index[0] + sphere_radius + 1),\n",
    "            max(0, max_suv_index[1] - sphere_radius):min(suvbw_organ.shape[1], max_suv_index[1] + sphere_radius + 1),\n",
    "            max(0, max_suv_index[2] - sphere_radius):min(suvbw_organ.shape[2], max_suv_index[2] + sphere_radius + 1)\n",
    "        ]\n",
    "\n",
    "        # Calculate SUV Peak for the organ (average value within the 1-cm^3 sphere)\n",
    "        # Calculate SUV Peak for the organ using median (more robust to noise)\n",
    "        suv_peak_organ = np.median(region_around_max_suv[region_around_max_suv > 0])\n",
    "        #suv_peak_organ = region_around_max_suv.mean()\n",
    "        print(\"SUV Peak:\")\n",
    "        print(suv_peak_organ)\n",
    "\n",
    "    else:\n",
    "        print(\"No valid data points in the segmented organ region. Unable to calculate SUV metrics.\")\n",
    "\n",
    "    return mean_suvbw_organ, suv_peak_organ, suv_max_organ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Output storage path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_excel_file_path = f\"C:/Personal/ABX/patient_2/Results/{metadata['patient_id']}_23_01_24_Final.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Main code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU Mean:\n",
      "49.87330965513282\n",
      "HU Standard Deviation:\n",
      "28.33698371959376\n",
      "Mask Volume (ml):\n",
      "5.610900455474853\n",
      "Mean SUVbw:\n",
      "0.8190398437821959\n",
      "SUV Max:\n",
      "1.0761061442853597\n",
      "SUV Peak:\n",
      "1.0438493378232379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kathir\\AppData\\Local\\Temp\\ipykernel_13796\\1218589794.py:44: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  existing_df = pd.concat([existing_df, new_df], ignore_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HU Mean:\n",
      "50.13368060542748\n",
      "HU Standard Deviation:\n",
      "25.16374751029642\n",
      "Mask Volume (ml):\n",
      "3.831834457397461\n",
      "Mean SUVbw:\n",
      "0.9171694022907495\n",
      "SUV Max:\n",
      "1.222258943859571\n",
      "SUV Peak:\n",
      "0.9782755981935909\n",
      "HU Mean:\n",
      "121.60717141265621\n",
      "HU Standard Deviation:\n",
      "32.241875316520826\n",
      "Mask Volume (ml):\n",
      "207.61575787353516\n",
      "Mean SUVbw:\n",
      "0.9518843883248221\n",
      "SUV Max:\n",
      "1.4942989300389617\n",
      "SUV Peak:\n",
      "1.3709464949477554\n",
      "HU and SUV Results appended to C:/Personal/ABX/patient_2/Results/PETCT_4ef69de4e1_23_01_24_Final.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Get a list of all NIfTI files in the \"segmented_organs\" folder\n",
    "segmented_nifti_paths = [os.path.join(segmented_organs_folder, file) for file in os.listdir(segmented_organs_folder) if file.endswith(\".nii.gz\")]\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "existing_df = pd.DataFrame(columns=[\n",
    "    'Patient ID', 'Organ', 'HU Mean', 'HU Std Dev', 'SUV Mean', 'SUV Peak', 'SUV Max', 'Mask Volume (ml)'\n",
    "])\n",
    "\n",
    "# Iterate through segmented organ NIfTI files\n",
    "for segmented_nifti_path in segmented_nifti_paths:\n",
    "    # Calculate HU metrics\n",
    "    hu_mean, hu_std, mask_volume_ml = calculate_hu_metrics(nifti_file_path_ct, segmented_nifti_path, metadata['rescale_slope_ct'], metadata['rescale_intercept_ct'])\n",
    "\n",
    "    # Calculate SUV metrics\n",
    "    #pet_weight = 65.0  # Assuming a constant weight for debuging\n",
    "    #pet_radionuclide_half_life = 6586.2  # Assuming a constant half-life for debugging\n",
    "    pet_mean_suvbw, pet_suv_peak, pet_suv_max = calculate_organ_suv(nifti_file_path_pet, segmented_nifti_path, metadata['weight'], metadata['radionuclide_half_life'], metadata['series_time'], metadata['acquisition_time'], metadata['radionuclide_total_dose'], metadata['rescale_slope_pet'], metadata['rescale_intercept_pet'])\n",
    "\n",
    "    # Extract organ name from the segmented nifti file name\n",
    "    organ_name = os.path.splitext(os.path.splitext(os.path.basename(segmented_nifti_path))[0])[0]\n",
    "\n",
    "    # Extract patient ID from nifti_file_path\n",
    "    match = re.search(r'/NIFTI/(.*?)/', nifti_file_path_ct)\n",
    "    if match:\n",
    "        patient_id = match.group(1)\n",
    "    else:\n",
    "        print(\"Unable to extract Patient ID from nifti_file_path.\")\n",
    "\n",
    "    # Determine the index of the next empty row\n",
    "    next_index = len(existing_df) + 1\n",
    "\n",
    "    # Append the new results to the existing DataFrame with the calculated index\n",
    "    new_data = {\n",
    "        'Patient ID': [patient_id],\n",
    "        'Organ': [organ_name],\n",
    "        'HU Mean': [hu_mean],\n",
    "        'HU Std Dev': [hu_std],\n",
    "        'SUV Mean': [pet_mean_suvbw],\n",
    "        'SUV Peak': [pet_suv_peak],\n",
    "        'SUV Max': [pet_suv_max],\n",
    "        'Mask Volume (ml)': [mask_volume_ml],\n",
    "    }\n",
    "\n",
    "    new_df = pd.DataFrame(new_data)\n",
    "    new_df.index = [next_index]\n",
    "\n",
    "    existing_df = pd.concat([existing_df, new_df], ignore_index=False)\n",
    "\n",
    "# Save the updated DataFrame to the Excel file without the index column\n",
    "existing_df.to_excel(existing_excel_file_path, index=False)\n",
    "\n",
    "# Print a message indicating successful export\n",
    "print(f\"HU and SUV Results appended to {existing_excel_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
